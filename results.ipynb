{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f25799",
   "metadata": {},
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import plotly.colors\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import statistics\n",
    "import pickle\n",
    "from pprint import pprint\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suurballe_node_disjoint(G: nx.Graph, s, t):\n",
    "    G_split = nx.DiGraph()\n",
    "\n",
    "    # Step 1: Split only intermediate nodes\n",
    "    for v in G.nodes:\n",
    "        if v not in (s, t):\n",
    "            G_split.add_edge(f\"{v}_in\", f\"{v}_out\", weight=0)\n",
    "\n",
    "    # Step 2: Replace edges appropriately\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        w = data['weight']\n",
    "\n",
    "        def map_in(x):\n",
    "            return f\"{x}_in\" if x not in (s, t) else x\n",
    "\n",
    "        def map_out(x):\n",
    "            return f\"{x}_out\" if x not in (s, t) else x\n",
    "\n",
    "        G_split.add_edge(map_out(u), map_in(v), weight=w)\n",
    "        G_split.add_edge(map_out(v), map_in(u), weight=w)\n",
    "\n",
    "    s_mod = s\n",
    "    t_mod = t\n",
    "\n",
    "    # Step 3: First shortest path\n",
    "    dist, paths = nx.single_source_dijkstra(G_split, s_mod, weight='weight')\n",
    "    if t_mod not in paths:\n",
    "        raise nx.NetworkXNoPath(f\"No path from {s} to {t}\")\n",
    "    path1 = paths[t_mod]\n",
    "\n",
    "    # Step 4: Build reduced cost graph\n",
    "    G_reduced = nx.DiGraph()\n",
    "    for u, v, data in G_split.edges(data=True):\n",
    "        if u in dist and v in dist:\n",
    "            new_w = data['weight'] + dist[u] - dist[v]\n",
    "            G_reduced.add_edge(u, v, weight=new_w, original_weight=data['weight'])\n",
    "\n",
    "    # Step 5: Remove path1 edges and reverse them\n",
    "    path_edges = list(zip(path1[:-1], path1[1:]))\n",
    "    for u, v in path_edges:\n",
    "        if G_reduced.has_edge(u, v):\n",
    "            G_reduced.remove_edge(u, v)\n",
    "        G_reduced.add_edge(v, u, weight=0)\n",
    "\n",
    "    # Step 6: Second shortest path\n",
    "    try:\n",
    "        path2 = nx.shortest_path(G_reduced, s_mod, t_mod, weight='weight')\n",
    "    except nx.NetworkXNoPath:\n",
    "        raise nx.NetworkXNoPath(\"No second disjoint path found\")\n",
    "\n",
    "    # Step 7: Combine edges and eliminate overlaps\n",
    "    edge_set = set()\n",
    "    for u, v in zip(path1[:-1], path1[1:]):\n",
    "        edge_set.add((u, v))\n",
    "    for u, v in zip(path2[:-1], path2[1:]):\n",
    "        if (v, u) in edge_set:\n",
    "            edge_set.remove((v, u))\n",
    "        else:\n",
    "            edge_set.add((u, v))\n",
    "\n",
    "    # Step 8: Build merged graph\n",
    "    merged = nx.DiGraph()\n",
    "    for u, v in edge_set:\n",
    "        merged.add_edge(u, v)\n",
    "\n",
    "    # Step 9: Extract disjoint paths\n",
    "    paths = list(nx.edge_disjoint_paths(merged, s_mod, t_mod))\n",
    "    if len(paths) < 2:\n",
    "        raise RuntimeError(\"Failed to extract two disjoint paths\")\n",
    "\n",
    "    # Step 10: Convert back to original node labels\n",
    "    def unsplit(path):\n",
    "        result = []\n",
    "        for node in path:\n",
    "            node_str = str(node)\n",
    "            if node_str.endswith('_in') or node_str.endswith('_out'):\n",
    "                base = int(node_str.split('_')[0])\n",
    "                if not result or result[-1] != base:\n",
    "                    result.append(base)\n",
    "            elif isinstance(node, int):\n",
    "                if not result or result[-1] != node:\n",
    "                    result.append(node)\n",
    "        return result\n",
    "\n",
    "\n",
    "    return unsplit(paths[0]), unsplit(paths[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687791e",
   "metadata": {},
   "source": [
    "## Earthquakes Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762ed1a7",
   "metadata": {},
   "source": [
    "### Shortest\n",
    "\n",
    "we are looking for shortest paths with onit weights on edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3678ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"infocom\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        G.edges[edge][\"weight\"] = 1\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"earthquakes_shortest.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248ecd8",
   "metadata": {},
   "source": [
    "### Independent\n",
    "\n",
    "take the logarithm of the edge fps, as they were independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d196ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"infocom\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        intersecting_srlgs = [\n",
    "            srlg for srlg in srlgs if G.edges[edge][\"id\"] in srlg[\"edges\"]\n",
    "        ]\n",
    "        G.edges[edge][\"weight\"] = -np.log10(\n",
    "            1 - sum(srlg[\"probability\"] for srlg in intersecting_srlgs)\n",
    "        )\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"earthquakes_independent.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130cbabe",
   "metadata": {},
   "source": [
    "## New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244dc12",
   "metadata": {},
   "source": [
    "### Shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        G.edges[edge][\"weight\"] = 1\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    other_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "        other_bound_ratios.appent(prob-min_prob / base_prob-min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"new_data_shortest.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2876f8",
   "metadata": {},
   "source": [
    "### Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d61677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        intersecting_srlgs = [\n",
    "            srlg for srlg in srlgs if G.edges[edge][\"id\"] in srlg[\"edges\"]\n",
    "        ]\n",
    "        G.edges[edge][\"weight\"] = -np.log10(\n",
    "            1 - sum(srlg[\"probability\"] for srlg in intersecting_srlgs)\n",
    "        )\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"new_data_independent.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733f2da",
   "metadata": {},
   "source": [
    "## New Data Edge-Disjoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d756c",
   "metadata": {},
   "source": [
    "### Shortest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee615055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        G.edges[edge][\"weight\"] = 1\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"edge_disjoint_shortest.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1afec3",
   "metadata": {},
   "source": [
    "### Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee79998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test data\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "# Make pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"graph_name\": pd.Series(dtype = str),\n",
    "    \"number_of_nodes\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_edges\": pd.Series(dtype=\"Int64\"),\n",
    "    \"number_of_srlgs\": pd.Series(dtype=\"Int64\"),\n",
    "    \"better\": pd.Series(dtype=\"Int64\"),\n",
    "    \"safer\": pd.Series(dtype=\"Int64\"),\n",
    "    \"shorter\": pd.Series(dtype=\"Int64\"),\n",
    "    \"same\": pd.Series(dtype=\"Int64\"),\n",
    "    \"worse\": pd.Series(dtype=\"Int64\"),\n",
    "    \"avg_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"avg_bandwidth_increase\": pd.Series(dtype = float),\n",
    "    \"best_unav_improvement\": pd.Series(dtype = float),\n",
    "    \"best_bandwidth_increase\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_min\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_max\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_avg\": pd.Series(dtype=float),\n",
    "    \"unav_over_lb_median\": pd.Series(dtype=float),\n",
    "})\n",
    "\n",
    "# Set graph_name to index\n",
    "df = df.set_index(\"graph_name\")\n",
    "\n",
    "# Fill it with the graph data\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    df.loc[graph_name, \"number_of_nodes\"] = len(G.nodes())\n",
    "    df.loc[graph_name, \"number_of_edges\"] = len(G.edges())\n",
    "    df.loc[graph_name, \"number_of_srlgs\"] = len(G.graph['srlgs'])\n",
    "\n",
    "# Fill emptry cells with zeros\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# loop through graphs\n",
    "for graph_name in solutions.keys():\n",
    "    #print(graph_name)\n",
    "    #print(f\"Graph: {graph_name}\")\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    srlgs = G.graph[\"srlgs\"]\n",
    "    for edge in G.edges():\n",
    "        intersecting_srlgs = [\n",
    "            srlg for srlg in srlgs if G.edges[edge][\"id\"] in srlg[\"edges\"]\n",
    "        ]\n",
    "        G.edges[edge][\"weight\"] = -np.log10(\n",
    "            1 - sum(srlg[\"probability\"] for srlg in intersecting_srlgs)\n",
    "        )\n",
    "\n",
    "    lower_bound_ratios = []\n",
    "    # loop through terminals\n",
    "    for terminal_index, (s, t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        # get baseline solution (node disjoint paths)\n",
    "        try:\n",
    "            disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "        except nx.NetworkXNoPath:\n",
    "            # edge case for the only node that is not 2-connected\n",
    "            # instead, take its neighbor\n",
    "            temp_s = s\n",
    "            temp_t = t\n",
    "            if temp_s == 23: temp_s = 17\n",
    "            if temp_t == 23: temp_t = 17\n",
    "            disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "            for path in disjoint_paths:\n",
    "                if path[0] == 17:\n",
    "                    path.insert(0, 23)\n",
    "                elif path[-1] == 17:\n",
    "                    path.append(23)\n",
    "        #print(f\"{terminal_index}\\t{s}\\t{t}\")\n",
    "\n",
    "        # get the failure probability magnitudes and lengths of the disjoint paths\n",
    "        base_prob = 1-get_surviving_probabilities_of_walks(G, disjoint_paths)[-2]\n",
    "        base_bandwidth = round(sum(len(disjoint_path) - 1 for disjoint_path in disjoint_paths), 4)\n",
    "\n",
    "        # get the safest paths\n",
    "        shortest_path = nx.shortest_path(G, s, t)\n",
    "        shortest_prob = 1-get_surviving_probabilities_of_walks(G, [shortest_path])[-1]\n",
    "        shortest_bandwidth = round(len(shortest_path) - 1, 4)\n",
    "\n",
    "        # now we should determine the number of solutions for different cases\n",
    "        our_probs = []\n",
    "        our_bandwidths = []\n",
    "        for n in range(2, 11):\n",
    "            walks = solutions[graph_name][\"terminals\"][(s, t)][\"min_cutting_prob\"][(n, n-1)][\"walks\"]\n",
    "            prob = 1-get_surviving_probabilities_of_walks(G, walks)[-2]\n",
    "            bandwidth = round(sum(len(walk) - 1 for walk in walks) / (n-1), 4)\n",
    "            if prob > shortest_prob:\n",
    "                break\n",
    "            our_probs.append(prob)\n",
    "            our_bandwidths.append(bandwidth)\n",
    "        #print(f\"base_prob: {base_prob}\")\n",
    "        min_prob = float(\"inf\")\n",
    "        min_prob_bandwidth = 0\n",
    "        for prob, bandwidth in zip(our_probs, our_bandwidths):\n",
    "            if prob < min_prob:\n",
    "                min_prob = prob\n",
    "                min_prob_bandwidth = bandwidth\n",
    "        #print(f\"min_prob: {min_prob}\")\n",
    "        prob_diff = base_prob - min_prob\n",
    "        bandwidth_diff = min_prob_bandwidth - base_bandwidth\n",
    "        prob_imp = (prob_diff / base_prob) * 100\n",
    "        bandwidth_imp = (bandwidth_diff / base_bandwidth) * 100\n",
    "\n",
    "        if prob_imp > df.loc[graph_name, \"best_unav_improvement\"]:\n",
    "            df.loc[graph_name, \"best_unav_improvement\"] = prob_imp\n",
    "            df.loc[graph_name, \"best_bandwidth_increase\"] = bandwidth_imp\n",
    "\n",
    "        df.loc[graph_name, \"avg_unav_improvement\"] += prob_imp/50\n",
    "        df.loc[graph_name, \"avg_bandwidth_increase\"] += bandwidth_imp/50\n",
    "\n",
    "        # Lower bound statistics\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    "\n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bound_ratios.append(prob / min_prob)\n",
    "\n",
    "        # Make statistics of the number of different cases\n",
    "        # +=2 because we have 50 inputs, and want the results in %\n",
    "        same = any(prob == base_prob and bandwidth == base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if same: \n",
    "            df.loc[graph_name, \"same\"] += 2\n",
    "        better = any(\n",
    "            prob < base_prob and bandwidth < base_bandwidth\n",
    "            for prob, bandwidth in zip(our_probs, our_bandwidths)\n",
    "        )\n",
    "        if better: # there is a better solution\n",
    "            df.loc[graph_name, \"better\"] += 2\n",
    "            continue \n",
    "        shorter = any(bandwidth < base_bandwidth for bandwidth in our_bandwidths)\n",
    "        safer = any(prob < base_prob for prob in our_probs)\n",
    "        if shorter or safer: # there is a shorter or safer solution\n",
    "            if shorter:\n",
    "                df.loc[graph_name, \"shorter\"] += 2\n",
    "            if safer:\n",
    "                df.loc[graph_name, \"safer\"] += 2\n",
    "            continue\n",
    "        if not same: # we have only worse solutions\n",
    "            df.loc[graph_name, \"worse\"] += 2\n",
    "            continue\n",
    "\n",
    "    df.loc[graph_name, \"unav_over_lb_min\"] = (min(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_max\"] = (max(lower_bound_ratios) -1 ) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_avg\"] = (sum(lower_bound_ratios) / len(lower_bound_ratios) -1) * 100\n",
    "    df.loc[graph_name, \"unav_over_lb_median\"] = (statistics.median(lower_bound_ratios) -1)*100\n",
    "\n",
    "df = df.round(2)\n",
    "print(df)\n",
    "output_path = os.path.join(\"figures\", \"htmls\", \"edge_disjoint_independent.html\")\n",
    "df.to_html(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9313b92",
   "metadata": {},
   "source": [
    "## Full graph 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dead0d",
   "metadata": {},
   "source": [
    "lower bound statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "method = \"min_cutting_prob\"\n",
    "solutions = {}\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "with open(path, \"rb\") as f:\n",
    "    solutions = pickle.load(f)\n",
    "\n",
    "max_name_len = max(len(name) for name in solutions.keys())\n",
    "name_col = \"Graph\"\n",
    "name_col_width = max(len(name_col), max_name_len)\n",
    "print(f\"{name_col:<{name_col_width}}  {'Min':>8}  {'Max':>8}  {'Avg':>8}  {'Median':>8}\")\n",
    "\n",
    "for graph_name in solutions.keys():\n",
    "    G = solutions[graph_name][\"graph\"]\n",
    "    lower_bouind_ratios = []\n",
    "\n",
    "    for i, (s,t) in enumerate(solutions[graph_name][\"terminals\"].keys()):\n",
    "        cutting_srlgs = []\n",
    "        for srlg in G.graph[\"srlgs\"]:\n",
    "            # Create a copy of the graph to avoid modifying the original\n",
    "            G_copy = G.copy()\n",
    "            # Remove the edges in the current SRLG\n",
    "            for edge_id in set(srlg[\"edges\"]):\n",
    "                u, v = G.graph[\"edge_by_id\"][edge_id]\n",
    "                G_copy.remove_edge(u, v)\n",
    " \n",
    "            # Check if s_id and t_id are still connected\n",
    "            if not nx.has_path(G_copy, s, t):\n",
    "                cutting_srlgs.append(srlg)\n",
    "        min_prob = sum(srlg[\"probability\"] for srlg in cutting_srlgs)\n",
    "\n",
    "        solution = solutions[graph_name][\"terminals\"][(s, t)][method][(2, 1)]\n",
    "        prob = 1-get_surviving_probabilities_of_walks(G, solution[\"walks\"])[-2]\n",
    "        lower_bouind_ratios.append(prob / min_prob)\n",
    "\n",
    "    minimum = min(lower_bouind_ratios)\n",
    "    maximum = max(lower_bouind_ratios)\n",
    "    average = sum(lower_bouind_ratios) / len(lower_bouind_ratios)\n",
    "    median = statistics.median(lower_bouind_ratios)\n",
    "    print(f\"{graph_name:<{name_col_width}}  {minimum:8.6f}  {maximum:8.6f}  {average:8.6f}  {median:8.6f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f50ad1",
   "metadata": {},
   "source": [
    "### Compare 1-backup solutions with 2 paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5e2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colors = px.colors.qualitative.Plotly\n",
    "\n",
    "# Load the results\n",
    "short_solutions = {}\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "with open(path, \"rb\") as f:\n",
    "    short_solutions = pickle.load(f)\n",
    "    \n",
    "# Test parameters\n",
    "graph_name = \"25_interoute_latlon\"\n",
    "G = short_solutions[graph_name][\"graph\"]\n",
    "method = \"min_cutting_prob\"\n",
    "figures = []\n",
    "\n",
    "for s, t in short_solutions[graph_name][\"terminals\"].keys():\n",
    "    # Our solution\n",
    "    solution = short_solutions[graph_name][\"terminals\"][(s, t)][method][2, 1]\n",
    "    walks = solution[\"walks\"]\n",
    "\n",
    "    # Disjoint paths\n",
    "    disjoint_paths = list(nx.node_disjoint_paths(G, s, t, cutoff=2))\n",
    "\n",
    "    # Get SRLGs intersecting the disjoint paths\n",
    "    edges_of_disjoint_paths = make_walks_by_edges(G, disjoint_paths)\n",
    "    disjoint_paths_edge_ids = set(eid for path in edges_of_disjoint_paths for eid in path)\n",
    "    intersecting_srlgs = [\n",
    "        srlg for srlg in G.graph['srlgs']\n",
    "        if set(srlg['edges']) & disjoint_paths_edge_ids\n",
    "    ]\n",
    "\n",
    "    # Top SRLGs\n",
    "    top_srlgs = sorted(intersecting_srlgs, key=lambda s: s['probability'], reverse=True)[:4]\n",
    "    H = planar_embed(G)\n",
    "    srlg_traces = get_srlg_traces(H, top_srlgs, dash='dot')\n",
    "    for idx, trace in enumerate(srlg_traces):\n",
    "        trace.line.color = default_colors[2 + idx]\n",
    "        trace.showlegend = (idx == 0)\n",
    "        trace.name = 'srlgs'\n",
    "\n",
    "    # Path traces\n",
    "    traces = get_path_traces(G, disjoint_paths + walks)\n",
    "\n",
    "    # Disjoint paths\n",
    "    disjoint_path_traces = traces[:2]\n",
    "    for i, trace in enumerate(disjoint_path_traces):\n",
    "        trace.showlegend = (i == 0)\n",
    "        trace.name = \"node disjoint paths\" if i == 0 else None\n",
    "        trace.line.color = default_colors[0]\n",
    "        if i == 1:\n",
    "            trace.line.dash = \"dash\"\n",
    "\n",
    "    # Our solution\n",
    "    solution_trace = traces[2:]\n",
    "    for i, trace in enumerate(solution_trace):\n",
    "        trace.showlegend = (i == 0)\n",
    "        trace.name = \"our solution\" if i == 0 else None\n",
    "        trace.line.color = default_colors[1]\n",
    "        if i == 1:\n",
    "            trace.line.dash = \"dash\"\n",
    "\n",
    "    # Base graph\n",
    "    edge_trace = get_edges_trace(G)\n",
    "    node_trace = get_nodes_trace(G, label='id')\n",
    "\n",
    "    # Change the colors of node s and t\n",
    "    node_colors = ['lightblue'] * len(node_trace.x)\n",
    "    node_labels = list(node_trace.text)\n",
    "    s_index = node_labels.index(str(s))\n",
    "    t_index = node_labels.index(str(t))\n",
    "    node_colors[s_index] = 'lightpink'\n",
    "    node_colors[t_index] = 'lightpink'\n",
    "    node_trace.marker.color = node_colors\n",
    "\n",
    "    # Combine everything\n",
    "    traces = disjoint_path_traces + solution_trace + [edge_trace, node_trace] + srlg_traces\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=traces,\n",
    "        layout=go.Layout(\n",
    "            margin=dict(b=5, l=5, r=5, t=5),\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, scaleanchor=\"x\"),\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0.2,\n",
    "            y=0.99,\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            font=dict(size=12),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    figures.append(fig)\n",
    "\n",
    "# Dash app\n",
    "app = Dash()\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.Div(\n",
    "            dcc.Graph(figure=figures[i]),\n",
    "            style={'width': '48%', 'display': 'inline-block', 'padding': '10px'}\n",
    "        )\n",
    "        for i in range(len(figures))\n",
    "    ])\n",
    "])\n",
    "app.run(port=8051)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b489ed",
   "metadata": {},
   "source": [
    "suurballe:\n",
    "26usa:\n",
    "fura: 35, 40 41\n",
    "italy:\n",
    "fura 4 (10, 16), 14 (9, 10), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3db5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colors = px.colors.qualitative.Plotly\n",
    "\n",
    "# Load the results\n",
    "short_solutions = {}\n",
    "path = os.path.join(\"results\", \"short_solutions_0.01.pkl\")\n",
    "with open(path, \"rb\") as f:\n",
    "    short_solutions = pickle.load(f)\n",
    "    \n",
    "# Test parameters\n",
    "graph_name = \"25_interoute_latlon\"\n",
    "G = short_solutions[graph_name][\"graph\"]\n",
    "method = \"min_cutting_prob\"\n",
    "figures = []\n",
    "# make weights for suurballe\n",
    "srlgs = G.graph[\"srlgs\"]\n",
    "for edge in G.edges():\n",
    "    intersecting_srlgs = [\n",
    "        srlg for srlg in srlgs if G.edges[edge][\"id\"] in srlg[\"edges\"]\n",
    "    ]\n",
    "    G.edges[edge][\"weight\"] = -np.log10(\n",
    "        1 - sum(srlg[\"probability\"] for srlg in intersecting_srlgs)\n",
    "    )\n",
    "\n",
    "for terminal_index, (s, t) in enumerate(short_solutions[graph_name][\"terminals\"].keys()):\n",
    "    # Our solution\n",
    "    solution = short_solutions[graph_name][\"terminals\"][(s, t)][method][2, 1]\n",
    "    walks = solution[\"walks\"]\n",
    "    \n",
    "\n",
    "    # Disjoint paths\n",
    "    try:\n",
    "        disjoint_paths = suurballe_node_disjoint(G, s, t)\n",
    "    except nx.NetworkXNoPath:\n",
    "        # edge case for the only node that is not 2-connected\n",
    "        # instead, take its neighbor\n",
    "        temp_s = s\n",
    "        temp_t = t\n",
    "        if temp_s == 23: temp_s = 17\n",
    "        if temp_t == 23: temp_t = 17\n",
    "        disjoint_paths = suurballe_node_disjoint(G, temp_s, temp_t)\n",
    "        for path in disjoint_paths:\n",
    "            if path[0] == 17:\n",
    "                path.insert(0, 23)\n",
    "            elif path[-1] == 17:\n",
    "                path.append(23)\n",
    "\n",
    "    # Get SRLGs intersecting the disjoint paths\n",
    "    edges_of_disjoint_paths = make_walks_by_edges(G, disjoint_paths)\n",
    "    disjoint_paths_edge_ids = set(eid for path in edges_of_disjoint_paths for eid in path)\n",
    "    intersecting_srlgs = [\n",
    "        srlg for srlg in G.graph['srlgs']\n",
    "        if set(srlg['edges']) & disjoint_paths_edge_ids\n",
    "    ]\n",
    "\n",
    "    # Top SRLGs\n",
    "    top_srlgs = sorted(intersecting_srlgs, key=lambda s: s['probability'], reverse=True)[:4]\n",
    "    H = planar_embed(G)\n",
    "    srlg_traces = get_srlg_traces(H, top_srlgs, dash='dot')\n",
    "    for idx, trace in enumerate(srlg_traces):\n",
    "        trace.line.color = default_colors[2 + idx]\n",
    "        trace.showlegend = (idx == 0)\n",
    "        trace.name = 'srlgs'\n",
    "\n",
    "    # Path traces\n",
    "    disjoint_paths = list(disjoint_paths)\n",
    "    traces = get_path_traces(G, disjoint_paths + walks)\n",
    "\n",
    "    # Disjoint paths\n",
    "    disjoint_path_traces = traces[:2]\n",
    "    for i, trace in enumerate(disjoint_path_traces):\n",
    "        trace.showlegend = (i == 0)\n",
    "        trace.name = \"node disjoint paths\" if i == 0 else None\n",
    "        trace.line.color = default_colors[0]\n",
    "        if i == 1:\n",
    "            trace.line.dash = \"dash\"\n",
    "\n",
    "    # Our solution\n",
    "    solution_trace = traces[2:]\n",
    "    for i, trace in enumerate(solution_trace):\n",
    "        trace.showlegend = (i == 0)\n",
    "        trace.name = \"our solution\" if i == 0 else None\n",
    "        trace.line.color = default_colors[1]\n",
    "        if i == 1:\n",
    "            trace.line.dash = \"dash\"\n",
    "\n",
    "    # Base graph\n",
    "    edge_trace = get_edges_trace(G)\n",
    "    node_trace = get_nodes_trace(G, label='id')\n",
    "\n",
    "    # Change the colors of node s and t\n",
    "    node_colors = ['lightblue'] * len(node_trace.x)\n",
    "    node_labels = list(node_trace.text)\n",
    "    s_index = node_labels.index(str(s))\n",
    "    t_index = node_labels.index(str(t))\n",
    "    node_colors[s_index] = 'lightpink'\n",
    "    node_colors[t_index] = 'lightpink'\n",
    "    node_trace.marker.color = node_colors\n",
    "\n",
    "    # Combine everything\n",
    "    traces = disjoint_path_traces + solution_trace + [edge_trace, node_trace] + srlg_traces\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=traces,\n",
    "        layout=go.Layout(\n",
    "            margin=dict(b=5, l=5, r=5, t=5),\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False, scaleanchor=\"x\"),\n",
    "            plot_bgcolor='white',\n",
    "            paper_bgcolor='white'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            x=0.2,\n",
    "            y=0.99,\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            font=dict(size=12),\n",
    "        ),\n",
    "        title=f\"Terminal pair {terminal_index}: s={s}, t={t}\",\n",
    "        title_x=0.5,  # centered\n",
    "        margin=dict(t=60)\n",
    "    )\n",
    "\n",
    "    figures.append(fig)\n",
    "\n",
    "# Dash app\n",
    "app = Dash()\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.Div(\n",
    "            dcc.Graph(figure=figures[i]),\n",
    "            style={'width': '48%', 'display': 'inline-block', 'padding': '10px'}\n",
    "        )\n",
    "        for i in range(len(figures))\n",
    "    ])\n",
    "])\n",
    "app.run(port=8051)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szakdolgozat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
